{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.96%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# REFERENCE: Time-series Generative Adversarial Networks\n",
    "\n",
    "# merge gen and not gen datased adding a binary label column\n",
    "# train a lstm model to predict the binary label \n",
    "# test the model on the test set\n",
    "# if the accuracy is high, the model is able to discriminate between generated and not generated data (the dataset are different) otherwise the model is not able to discriminate between\n",
    "#    the two datasets (the dataset are similar)\n",
    "# ho fatto una prova con solo il dataset non generato e l'accuracy Ã¨ ovviamente di circa il 50% (TODELETE)\n",
    "\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, df): # df in input is the merged dataset with the binary label \"generated\"\n",
    "        self.df = df\n",
    "\n",
    "    def preprocess(self):\n",
    "        self._remove_columns()\n",
    "        self._one_hot_encode()\n",
    "        self.zscore()\n",
    "        self._binarization()\n",
    "        return self.df\n",
    "    \n",
    "    def zscore(self):\n",
    "        self.df['PRICE'] = (self.df['PRICE'] - self.df['PRICE'].mean()) / self.df['PRICE'].std()\n",
    "        self.df['SIZE'] = (self.df['SIZE'] - self.df['SIZE'].mean()) / self.df['SIZE'].std()\n",
    "        self.df['ask_price_1'] = (self.df['ask_price_1'] - self.df['ask_price_1'].mean()) / self.df['ask_price_1'].std()\n",
    "        self.df['ask_size_1'] = (self.df['ask_size_1'] - self.df['ask_size_1'].mean()) / self.df['ask_size_1'].std()\n",
    "        self.df['bid_price_1'] = (self.df['bid_price_1'] - self.df['bid_price_1'].mean()) / self.df['bid_price_1'].std()\n",
    "        self.df['bid_size_1'] = (self.df['bid_size_1'] - self.df['bid_size_1'].mean()) / self.df['bid_size_1'].std()\n",
    "        #self.df['ORDER_VOLUME_IMBALANCE'] = (self.df['ORDER_VOLUME_IMBALANCE'] - self.df['ORDER_VOLUME_IMBALANCE'].mean()) / self.df['ORDER_VOLUME_IMBALANCE'].std()\n",
    "        self.df['VWAP'] = self.df['VWAP'].fillna(0)\n",
    "        self.df['VWAP'] = (self.df['VWAP'] - self.df['VWAP'].mean()) / self.df['VWAP'].std()\n",
    "        self.df['MID_PRICE'] = (self.df['MID_PRICE'] - self.df['MID_PRICE'].mean()) / self.df['MID_PRICE'].std() # not in predictive\n",
    "\n",
    "    def _one_hot_encode(self):\n",
    "        self.df = pd.get_dummies(self.df, columns=['TYPE'])\n",
    "\n",
    "    def _remove_columns(self):\n",
    "        self.df = self.df.drop(['ORDER_ID', 'SPREAD', 'ORDER_VOLUME_IMBALANCE'], axis=1)\n",
    "        self.df = self.df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "    def _binarization(self):\n",
    "        self.df['BUY_SELL_FLAG'] = self.df['BUY_SELL_FLAG'].apply(lambda x: 1 if x == 'True' else 0)\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device, non_blocking=True)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device, non_blocking=True)\n",
    "        out, _ = self.lstm(x, (h0, c0))  \n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, test_loader, criterion, optimizer, device):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "\n",
    "    def train(self, epochs):\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            for inputs, labels in self.train_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(inputs)\n",
    "                loss = self.criterion(output, labels.unsqueeze(1))\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        test_preds = torch.Tensor().to(self.device, non_blocking=True)\n",
    "        test_labels = torch.Tensor().to(self.device, non_blocking=True)\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.test_loader:\n",
    "                output = self.model(inputs)\n",
    "                test_preds = torch.cat((test_preds, output), dim=0)\n",
    "                test_labels = torch.cat((test_labels, labels.unsqueeze(1)), dim=0)\n",
    "        test_preds = torch.sigmoid(test_preds)\n",
    "        test_preds_binary = (test_preds > 0.5).float()\n",
    "        accuracy = (test_preds_binary == test_labels).sum().item() / test_labels.numel()\n",
    "        print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "#################################################################################################################################################################################################\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def merge_dataframes_with_labels(d1, d2):\n",
    "    d1['generated'] = 0\n",
    "    d2['generated'] = 1\n",
    "    merged_df = pd.concat([d1, d2])\n",
    "    # shuffle the dataset\n",
    "    # merged_df = merged_df.sample(frac=1).reset_index(drop=True)\n",
    "    return merged_df\n",
    "\n",
    "df1 = pd.read_csv(r'C:\\Users\\marco\\OneDrive\\Documenti\\AFC\\afc_project\\Diffusion-Models-for-Time-Series\\data\\real_orders.csv') \n",
    "df2 = pd.read_csv(r'C:\\Users\\marco\\OneDrive\\Documenti\\AFC\\afc_project\\Diffusion-Models-for-Time-Series\\data\\generated_orders.csv')\n",
    "\n",
    "# remove the first 15 minutes of the generated dataset\n",
    "df2[\"Time\"] = df2['Unnamed: 0'].str.slice(11, 19)\n",
    "df2 = df2.query(\"Time >= '09:45:00'\")\n",
    "df2 = df2.drop(['Time'], axis=1)\n",
    "\n",
    "# undersampling on the real dataset\n",
    "n_remove = len(df1) - len(df2)\n",
    "drop_indices = np.random.choice(df1.index, n_remove, replace=False)\n",
    "df1 = df1.drop(drop_indices)\n",
    "\n",
    "df = Preprocessor(merge_dataframes_with_labels(df1, df2)).preprocess()\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "df2 = df.copy()\n",
    "\n",
    "# df2 deve essere composto solo da istanze cui generated = 0\n",
    "df2 = df2[df2['generated'] == 1]\n",
    "\n",
    "# Assuming df is already preprocessed\n",
    "features2 = df2.drop('generated', axis=1).values\n",
    "labels2 = df2['generated'].values\n",
    "\n",
    "# Reshape input to be 3D [samples, timesteps, features]\n",
    "features2 = features2.reshape((features2.shape[0], 1, features2.shape[1]))\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_X2, test_X2, train_y2, test_y2 = train_test_split(features2, labels2, test_size=0.4, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_X2 = torch.tensor(train_X2, dtype=torch.float32)\n",
    "train_y2 = torch.tensor(train_y2, dtype=torch.float32)\n",
    "test_X2 = torch.tensor(test_X2, dtype=torch.float32)\n",
    "test_y2 = torch.tensor(test_y2, dtype=torch.float32)\n",
    "\n",
    "# Create data loaders\n",
    "train_data2 = TensorDataset(train_X2, train_y2)\n",
    "train_loader2 = DataLoader(train_data2, batch_size=48)\n",
    "test_data2 = TensorDataset(test_X2, test_y2)\n",
    "test_loader2 = DataLoader(test_data2, batch_size=48)\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "# Assuming df is already preprocessed\n",
    "features = df.drop('generated', axis=1).values\n",
    "labels = df['generated'].values\n",
    "\n",
    "# Reshape input to be 3D [samples, timesteps, features]\n",
    "features = features.reshape((features.shape[0], 1, features.shape[1]))\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_X, test_X, train_y, test_y = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_X = torch.tensor(train_X, dtype=torch.float32)\n",
    "train_y = torch.tensor(train_y, dtype=torch.float32)\n",
    "test_X = torch.tensor(test_X, dtype=torch.float32)\n",
    "test_y = torch.tensor(test_y, dtype=torch.float32)\n",
    "\n",
    "# Create data loaders\n",
    "train_data = TensorDataset(train_X, train_y)\n",
    "train_loader = DataLoader(train_data, batch_size=48)\n",
    "test_data = TensorDataset(test_X, test_y)\n",
    "test_loader = DataLoader(test_data, batch_size=48)\n",
    "\n",
    "model = LSTMModel(input_size=train_X.shape[2], hidden_size=128, num_layers=1, output_size=1)\n",
    "model.to(device)\n",
    "\n",
    "trainer = Trainer(model=model, train_loader=train_loader, test_loader=test_loader, criterion=nn.BCEWithLogitsLoss(), optimizer=torch.optim.Adam(model.parameters(), lr=0.001), device=device)\n",
    "trainer.train(epochs=100)\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real data:\n",
      "Test MSE: 10.091599464416504\n",
      "Generated data:\n",
      "Test MSE: 162.6494140625\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# given real data and generated data\n",
    "# train a lstm with real data, train a lstm with generated data\n",
    "# test the two lstm on real data test set\n",
    "\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, df): \n",
    "        self.df = df\n",
    "\n",
    "    def preprocess(self):\n",
    "        self._check_inf()\n",
    "        self._remove_columns()\n",
    "        self._one_hot_encode()\n",
    "        self.zscore()\n",
    "        self._binarization()\n",
    "        return self.df\n",
    "    \n",
    "    def zscore(self):\n",
    "        self.df['PRICE'] = (self.df['PRICE'] - self.df['PRICE'].mean()) / self.df['PRICE'].std()\n",
    "        self.df['SIZE'] = (self.df['SIZE'] - self.df['SIZE'].mean()) / self.df['SIZE'].std()\n",
    "        self.df['ask_price_1'] = (self.df['ask_price_1'] - self.df['ask_price_1'].mean()) / self.df['ask_price_1'].std()\n",
    "        self.df['ask_size_1'] = (self.df['ask_size_1'] - self.df['ask_size_1'].mean()) / self.df['ask_size_1'].std()\n",
    "        self.df['bid_price_1'] = (self.df['bid_price_1'] - self.df['bid_price_1'].mean()) / self.df['bid_price_1'].std()\n",
    "        self.df['bid_size_1'] = (self.df['bid_size_1'] - self.df['bid_size_1'].mean()) / self.df['bid_size_1'].std()\n",
    "        #self.df['ORDER_VOLUME_IMBALANCE'] = (self.df['ORDER_VOLUME_IMBALANCE'] - self.df['ORDER_VOLUME_IMBALANCE'].mean()) / self.df['ORDER_VOLUME_IMBALANCE'].std()\n",
    "        self.df['VWAP'] = self.df['VWAP'].fillna(0)\n",
    "        self.df['VWAP'] = (self.df['VWAP'] - self.df['VWAP'].mean()) / self.df['VWAP'].std()\n",
    "\n",
    "    def _one_hot_encode(self):\n",
    "        self.df = pd.get_dummies(self.df, columns=['TYPE'])\n",
    "\n",
    "    def _remove_columns(self):\n",
    "        self.df = self.df.drop(['ORDER_ID', 'SPREAD', 'ORDER_VOLUME_IMBALANCE'], axis=1)\n",
    "        self.df = self.df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "    def _binarization(self):\n",
    "        self.df['BUY_SELL_FLAG'] = self.df['BUY_SELL_FLAG'].apply(lambda x: 1 if x == 'True' else 0)\n",
    "\n",
    "    def _check_inf(self):\n",
    "        #self.df[self.df.ORDER_VOLUME_IMBALANCE != np.inf]\n",
    "        self.df[self.df.MID_PRICE != np.inf]\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device, non_blocking=True)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device, non_blocking=True)\n",
    "        out, _ = self.lstm(x, (h0, c0))  \n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, test_loader, criterion, optimizer, device):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "\n",
    "    def train(self, epochs):\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            for inputs, labels in self.train_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(inputs)\n",
    "                loss = self.criterion(output, labels.unsqueeze(1))\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        test_preds = torch.Tensor().to(self.device, non_blocking=True)\n",
    "        test_labels = torch.Tensor().to(self.device, non_blocking=True)\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.test_loader:\n",
    "                #print(inputs)\n",
    "                output = self.model(inputs)\n",
    "                test_preds = torch.cat((test_preds, output), dim=0)\n",
    "                test_labels = torch.cat((test_labels, labels), dim=0)\n",
    "                #print(\"Predicted Values:\", output)\n",
    "        mse = nn.functional.mse_loss(test_preds, test_labels.unsqueeze(1)).item()\n",
    "        print(f'Test MSE: {mse}')\n",
    "        #mae = nn.functional.l1_loss(test_preds, test_labels.unsqueeze(1)).item()\n",
    "        #print(f'Test MAE: {mae}')\n",
    "\n",
    "#################################################################################################################################################################################################\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "df_r = pd.read_csv(r'C:\\Users\\marco\\OneDrive\\Documenti\\AFC\\afc_project\\Diffusion-Models-for-Time-Series\\data\\real_orders.csv')\n",
    "df_g = pd.read_csv(r'C:\\Users\\marco\\OneDrive\\Documenti\\AFC\\afc_project\\Diffusion-Models-for-Time-Series\\data\\generated_orders.csv')\n",
    "\n",
    "# remove the first 15 minutes of the generated dataset\n",
    "df_g[\"Time\"] = df_g['Unnamed: 0'].str.slice(11, 19)\n",
    "df_g = df_g.query(\"Time >= '09:45:00'\")\n",
    "df_g = df_g.drop(['Time'], axis=1)\n",
    "\n",
    "# undersampling on the real dataset\n",
    "n_remove = len(df_r) - len(df_g)\n",
    "drop_indices = np.random.choice(df_r.index, n_remove, replace=False)\n",
    "df_r = df_r.drop(drop_indices)\n",
    "\n",
    "\n",
    "df_r = Preprocessor(df_r).preprocess()\n",
    "df_g = Preprocessor(df_g).preprocess()\n",
    "\n",
    "'''\n",
    "# Check for NaN, null, inf, and missing values in df_g\n",
    "nan_columns = df_g.columns[df_g.isna().any()].tolist()\n",
    "null_columns = df_g.columns[df_g.isnull().any()].tolist()\n",
    "inf_columns = df_g.columns[(df_g == np.inf).any()].tolist()\n",
    "missing_columns = df_g.columns[df_g.isin([np.nan, np.inf, -np.inf, None]).any()].tolist()\n",
    "\n",
    "# Print the columns with NaN values\n",
    "print(\"Columns with NaN values:\", nan_columns)\n",
    "\n",
    "# Print the columns with null values\n",
    "print(\"Columns with null values:\", null_columns)\n",
    "\n",
    "# Print the columns with inf values\n",
    "print(\"Columns with inf values:\", inf_columns)\n",
    "\n",
    "# Print the columns with missing values (NaN, null, inf)\n",
    "print(\"Columns with missing values:\", missing_columns)\n",
    "\n",
    "\n",
    "# stampa colonne di df_r e df_g e i loro tipi\n",
    "# print(df_r.columns, df_g.columns)\n",
    "'''\n",
    "\n",
    "############ TEST \"real\" lstm on \"real\" test set ############\n",
    "\n",
    "# Assuming df is already preprocessed\n",
    "features_r = df_r.drop('MID_PRICE', axis=1).values\n",
    "labels_r = df_r['MID_PRICE'].values\n",
    "\n",
    "# Reshape input to be 3D [samples, timesteps, features]\n",
    "features_r = features_r.reshape((features_r.shape[0], 1, features_r.shape[1]))\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_X_r, test_X_r, train_y_r, test_y_r = train_test_split(features_r, labels_r, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_X_r = torch.tensor(train_X_r, dtype=torch.float32)\n",
    "train_y_r = torch.tensor(train_y_r, dtype=torch.float32)\n",
    "test_X_r = torch.tensor(test_X_r, dtype=torch.float32)\n",
    "test_y_r = torch.tensor(test_y_r, dtype=torch.float32)\n",
    "\n",
    "# Create data loaders\n",
    "train_data_r = TensorDataset(train_X_r, train_y_r)\n",
    "train_loader_r = DataLoader(train_data_r, batch_size=48)\n",
    "test_data_r = TensorDataset(test_X_r, test_y_r)\n",
    "test_loader_r = DataLoader(test_data_r, batch_size=48)\n",
    "\n",
    "model_r = LSTMModel(input_size=train_X_r.shape[2], hidden_size=128, num_layers=2, output_size=1)\n",
    "model_r.to(device)\n",
    "\n",
    "trainer_r = Trainer(model=model_r, train_loader=train_loader_r, test_loader=test_loader_r, criterion=nn.MSELoss(), optimizer=torch.optim.Adam(model_r.parameters(), lr=0.001), device=device)\n",
    "trainer_r.train(epochs=100)\n",
    "print(\"Real data:\")\n",
    "trainer_r.test()\n",
    "\n",
    "############ TEST \"generated\" lstm on \"real\" test set ############\n",
    "\n",
    "# Assuming df is already preprocessed\n",
    "features_g = df_g.drop('MID_PRICE', axis=1).values\n",
    "labels_g = df_g['MID_PRICE'].values\n",
    "\n",
    "# Reshape input to be 3D [samples, timesteps, features]\n",
    "features_g = features_g.reshape((features_g.shape[0], 1, features_g.shape[1]))\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_X_g, test_X_g, train_y_g, test_y_g = train_test_split(features_g, labels_g, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_X_g = torch.tensor(train_X_g, dtype=torch.float32)\n",
    "train_y_g = torch.tensor(train_y_g, dtype=torch.float32)\n",
    "test_X_g = torch.tensor(test_X_g, dtype=torch.float32)\n",
    "test_y_g = torch.tensor(test_y_g, dtype=torch.float32)\n",
    "\n",
    "# Create data loaders\n",
    "train_data_g = TensorDataset(train_X_g, train_y_g)\n",
    "train_loader_g = DataLoader(train_data_g, batch_size=48)\n",
    "test_data_g = TensorDataset(test_X_g, test_y_g)\n",
    "test_loader_g = DataLoader(test_data_g, batch_size=48)\n",
    "\n",
    "model_g = LSTMModel(input_size=train_X_g.shape[2], hidden_size=128, num_layers=2, output_size=1)\n",
    "model_g.to(device)\n",
    "\n",
    "trainer_g = Trainer(model=model_g, train_loader=train_loader_g, test_loader=test_loader_r, criterion=nn.MSELoss(), optimizer=torch.optim.Adam(model_g.parameters(), lr=0.001), device=device)\n",
    "trainer_g.train(epochs=100)\n",
    "print(\"Generated data:\")\n",
    "trainer_g.test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27476\n",
      "27476\n"
     ]
    }
   ],
   "source": [
    "df_p = pd.read_csv(r'C:\\Users\\marco\\OneDrive\\Documenti\\AFC\\afc_project\\Diffusion-Models-for-Time-Series\\data\\generated_orders.csv')\n",
    "\n",
    "print(len(df_p))\n",
    "\n",
    "# cancella le istanze che hanno come ORDER_VOLUME_IMBALANCE inf\n",
    "df_p = df_p[df_p.MID_PRICE != np.inf]\n",
    "\n",
    "print(len(df_p))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
